<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Descriptor Capture Tool</title>
    <script async src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 600px;
            width: 100%;
            padding: 40px;
            text-align: center;
        }
        h1 { color: #333; margin-bottom: 10px; font-size: 28px; }
        p { color: #666; margin-bottom: 20px; font-size: 14px; }
        .video-container {
            background: #000;
            border-radius: 15px;
            overflow: hidden;
            margin: 20px 0;
            width: 100%;
            aspect-ratio: 4/3;
        }
        video { width: 100%; height: 100%; object-fit: cover; }
        button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 30px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            margin: 10px;
            transition: all 0.3s ease;
        }
        button:hover { transform: translateY(-2px); box-shadow: 0 10px 20px rgba(102, 126, 234, 0.3); }
        .status {
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
            font-weight: 600;
        }
        .status.success { background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
        .status.error { background: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
        .status.info { background: #d1ecf1; color: #0c5460; border: 1px solid #bee5eb; }
        .output {
            background: #f8f9fa;
            border: 2px solid #e8edf2;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
            text-align: left;
            max-height: 150px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            color: #333;
        }
        .captured-image {
            border-radius: 12px;
            max-width: 200px;
            margin: 20px auto;
            overflow: hidden;
        }
        .captured-image img {
            width: 100%;
            height: auto;
            border: 3px solid #667eea;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üë§ Facial Descriptor Capture</h1>
        <p>Capture your face to update your account in the database</p>

        <div id="status" class="status info" style="display: none;"></div>

        <div class="video-container" id="videoContainer" style="display: none;">
            <video id="video" autoplay playsinline></video>
        </div>

        <div id="capturedImageDisplay"></div>

        <button id="startBtn" onclick="startCamera()">üì∑ Start Camera</button>
        <button id="captureBtn" onclick="captureFace()" style="display: none;">üì∏ Capture Face</button>
        <button id="updateBtn" onclick="updateDatabase()" style="display: none; background: linear-gradient(135deg, #4caf50 0%, #45a049 100%);">‚úì Update Database</button>
        <button onclick="location.reload()">üîÑ Reset</button>

        <div class="output" id="output" style="display: none;"></div>
    </div>

    <script>
        const API_URL = 'http://localhost:5000/api';
        let modelsLoaded = false;
        let stream = null;
        let facialDescriptor = null;
        let facialData = null;

        async function loadFaceModels() {
            if (modelsLoaded) return;
            try {
                const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                    faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL)
                ]);
                modelsLoaded = true;
                log('‚úÖ Face-API models loaded successfully');
            } catch (error) {
                log('‚ùå Error loading Face-API models: ' + error.message);
            }
        }

        window.addEventListener('load', loadFaceModels);

        function log(message) {
            const output = document.getElementById('output');
            output.style.display = 'block';
            output.innerHTML += message + '<br>';
            output.scrollTop = output.scrollHeight;
            console.log(message);
        }

        function showStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = 'status ' + type;
            status.style.display = 'block';
        }

        async function startCamera() {
            try {
                showStatus('‚è≥ Requesting camera access...', 'info');
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } }
                });
                document.getElementById('video').srcObject = stream;
                document.getElementById('videoContainer').style.display = 'block';
                document.getElementById('startBtn').style.display = 'none';
                document.getElementById('captureBtn').style.display = 'block';
                showStatus('‚úÖ Camera ready. Position your face and click Capture Face.', 'success');
                log('üì∑ Camera started');
            } catch (error) {
                showStatus('‚ùå Camera access denied: ' + error.message, 'error');
                log('‚ùå Camera error: ' + error.message);
            }
        }

        async function extractFacialDescriptor(canvas) {
            try {
                if (!modelsLoaded) {
                    log('‚è≥ Waiting for Face-API models...');
                    let attempts = 0;
                    while (!modelsLoaded && attempts < 600) {
                        await new Promise(r => setTimeout(r, 100));
                        attempts++;
                    }
                    if (!modelsLoaded) {
                        log('‚ùå Models failed to load');
                        return null;
                    }
                }

                log('üîç Detecting face...');
                const detections = await faceapi
                    .detectAllFaces(canvas, new faceapi.TinyFaceDetectorOptions({ inputSize: 416 }))
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                if (detections.length === 0) {
                    log('‚ùå No face detected');
                    return null;
                }

                const descriptor = detections[0].descriptor;
                if (!descriptor || descriptor.length !== 128) {
                    log(`‚ùå Invalid descriptor size: ${descriptor?.length || 'null'}D`);
                    return null;
                }

                log(`‚úÖ Extracted 128D facial descriptor`);
                log(`   Values: [${Array.from(descriptor).slice(0, 5).map(v => v.toFixed(3)).join(', ')}...]`);
                return descriptor;
            } catch (error) {
                log('‚ùå Error: ' + error.message);
                return null;
            }
        }

        async function captureFace() {
            const video = document.getElementById('video');
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');

            showStatus('‚è≥ Capturing face...', 'info');

            try {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                ctx.drawImage(video, 0, 0);

                log(`üìê Canvas: ${canvas.width}x${canvas.height}`);
                facialDescriptor = await extractFacialDescriptor(canvas);
                
                if (!facialDescriptor) {
                    showStatus('‚ùå Face detection failed', 'error');
                    return;
                }

                facialData = canvas.toDataURL('image/jpeg');
                document.getElementById('capturedImageDisplay').innerHTML = `
                    <div class="captured-image"><img src="${facialData}"></div>
                `;
                
                showStatus('‚úÖ Face captured successfully! Click Update Database to save.', 'success');
                document.getElementById('captureBtn').style.display = 'none';
                document.getElementById('updateBtn').style.display = 'block';
                
                if (stream) {
                    stream.getTracks().forEach(track => track.stop());
                    stream = null;
                }
            } catch (error) {
                showStatus('‚ùå Error: ' + error.message, 'error');
                log('‚ùå Capture error: ' + error.message);
            }
        }

        async function updateDatabase() {
            if (!facialDescriptor) {
                showStatus('‚ùå No facial descriptor captured', 'error');
                return;
            }

            showStatus('‚è≥ Updating database...', 'info');
            log('üì§ Sending facial descriptor to backend...');

            try {
                const response = await fetch(`${API_URL}/update-user-facial`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        email: 'priyanshu@smartlibrary.local',
                        facial_descriptor: Array.from(facialDescriptor)
                    })
                });

                const data = await response.json();
                log(`Backend response: ${JSON.stringify(data)}`);

                if (data.success) {
                    showStatus('‚úÖ Database updated successfully! Your facial data is now registered.', 'success');
                    log('üéâ Your face is now linked to your account!');
                    log('üìù You can now login with:');
                    log('   Email: priyanshu@smartlibrary.local');
                    log('   Password: priyanshu123');
                    log('   Face: YOUR ACTUAL FACE');
                    document.getElementById('updateBtn').style.display = 'none';
                } else {
                    showStatus('‚ùå ' + (data.message || 'Database update failed'), 'error');
                    log('‚ùå Error: ' + data.message);
                }
            } catch (error) {
                showStatus('‚ùå Error: ' + error.message, 'error');
                log('‚ùå Request error: ' + error.message);
            }
        }

        // Initialize
        log('üöÄ Facial Descriptor Capture Tool initialized');
        log('Step 1: Click "Start Camera"');
        log('Step 2: Position your face and click "Capture Face"');
        log('Step 3: Click "Update Database" to save');
    </script>
</body>
</html>
